# utils/storage.py
import json
import os
import logging
import sqlite3
import threading
import re
import uuid
from datetime import datetime
import time
from typing import Any, Optional, List
import config
from utils.user_context import get_current_user_id

logger = logging.getLogger("Amaya.Storage")
event_logger = logging.getLogger("Amaya.EventBus")


def build_reminder_id(run_at: float) -> str:
    """åŸºäºæ—¶é—´æˆ³å’Œéšæœºç†µç”ŸæˆçŸ­ IDï¼Œé¿å…åŒç§’å†²çªã€‚"""
    import secrets
    ts_part = format(int(run_at * 1000), 'x')[-8:]
    rand_part = secrets.token_hex(3)
    return f"r{ts_part}{rand_part}"


# å…¨å±€æ–‡ä»¶é”ï¼Œé˜²æ­¢å¹¶å‘è¯»å†™
_file_locks: dict[str, threading.Lock] = {}
_locks_lock = threading.Lock()  # ä¿æŠ¤ _file_locks çš„é”

def _get_file_lock(path: str) -> threading.Lock:
    """è·å–æŒ‡å®šæ–‡ä»¶çš„é”"""
    with _locks_lock:
        if path not in _file_locks:
            _file_locks[path] = threading.Lock()
        return _file_locks[path]

# å®šä¹‰è®°å¿†åº“çš„ç‰©ç†è·¯å¾„
DATA_DIR = "data/memory_bank"
os.makedirs(DATA_DIR, exist_ok=True)
_legacy_memory_migrated = False

# --- æ–‡ä»¶è·¯å¾„æ³¨å†Œè¡¨ ---
# é›†ä¸­ç®¡ç†æ‰€æœ‰æ•°æ®æ–‡ä»¶è·¯å¾„
FILES = {
    "meta": os.path.join("data", "meta.json"),
    "pending_reminders": os.path.join("data", "pending_reminders.json"),
    "sys_bus": os.path.join("data", "sys_event_bus.jsonl"),
    "short_term_memory": os.path.join("data", "short_term_memory.json")
}

# --- SQLite å­˜å‚¨ ---
DB_PATH = config.DB_PATH
db_dir = os.path.dirname(DB_PATH)
if db_dir:
    os.makedirs(db_dir, exist_ok=True)
_db_lock = threading.Lock()


def _get_db_connection() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH, timeout=30)
    conn.row_factory = sqlite3.Row
    return conn


def _load_json_file(path: str, default: Optional[Any] = None) -> Any:
    if not os.path.exists(path):
        return default
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        logger.error(f"JSON è§£æå¤±è´¥ {path}: {e}")
        return default
    except IOError as e:
        logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {path}: {e}")
        return default


def _init_db() -> None:
    with _db_lock, _get_db_connection() as conn:
        conn.execute("PRAGMA journal_mode=WAL;")
        conn.execute("""
            CREATE TABLE IF NOT EXISTS users (
                user_id TEXT PRIMARY KEY,
                display_name TEXT,
                created_at REAL NOT NULL
            )
        """)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS user_mappings (
                platform TEXT NOT NULL,
                external_id TEXT NOT NULL,
                user_id TEXT NOT NULL,
                created_at REAL NOT NULL,
                PRIMARY KEY (platform, external_id)
            )
        """)
        conn.execute("CREATE INDEX IF NOT EXISTS idx_user_mappings_user ON user_mappings(user_id)")
        conn.execute("""
            CREATE TABLE IF NOT EXISTS meta (
                user_id TEXT NOT NULL,
                key TEXT NOT NULL,
                value TEXT NOT NULL,
                PRIMARY KEY (user_id, key)
            )
        """)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS pending_reminders (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                run_at REAL NOT NULL,
                prompt TEXT NOT NULL
            )
        """)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS short_term_memory (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                role TEXT NOT NULL,
                text TEXT NOT NULL,
                timestamp REAL NOT NULL
            )
        """)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS sys_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                event_id TEXT,
                event_type TEXT,
                payload TEXT NOT NULL,
                status TEXT NOT NULL DEFAULT 'pending',
                created_at REAL NOT NULL,
                processed_at REAL
            )
        """)
        conn.execute("CREATE INDEX IF NOT EXISTS idx_sys_events_status ON sys_events(status)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_sys_events_type ON sys_events(event_type)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_sys_events_user ON sys_events(user_id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_pending_reminders_user ON pending_reminders(user_id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_memory_user ON short_term_memory(user_id)")

    _migrate_schema()
    _migrate_json_to_db()


def _get_table_columns(conn: sqlite3.Connection, table: str) -> set[str]:
    rows = conn.execute(f"PRAGMA table_info({table})").fetchall()
    return {row[1] for row in rows}


def _migrate_schema() -> None:
    with _db_lock, _get_db_connection() as conn:
        # meta table migration (add user_id dimension)
        cols = _get_table_columns(conn, "meta")
        if cols and "user_id" not in cols:
            conn.execute("ALTER TABLE meta RENAME TO meta_legacy")
            conn.execute("""
                CREATE TABLE meta (
                    user_id TEXT NOT NULL,
                    key TEXT NOT NULL,
                    value TEXT NOT NULL,
                    PRIMARY KEY (user_id, key)
                )
            """)
            conn.execute(
                "INSERT INTO meta (user_id, key, value) SELECT ?, key, value FROM meta_legacy",
                (config.DEFAULT_USER_ID,)
            )
            conn.execute("DROP TABLE meta_legacy")

        for table in ("pending_reminders", "short_term_memory", "sys_events"):
            cols = _get_table_columns(conn, table)
            if cols and "user_id" not in cols:
                conn.execute(f"ALTER TABLE {table} ADD COLUMN user_id TEXT")
                conn.execute(
                    f"UPDATE {table} SET user_id = ? WHERE user_id IS NULL",
                    (config.DEFAULT_USER_ID,)
                )


def _migrate_json_to_db() -> None:
    """
    å°†æ—§ç‰ˆ JSON æ–‡ä»¶è¿ç§»åˆ° SQLiteï¼ˆä»…åœ¨è¡¨ä¸ºç©ºæ—¶æ‰§è¡Œï¼‰ã€‚
    ä¿ç•™åŸæ–‡ä»¶ä»¥ä¾¿å›æ»š/å®¡è®¡ã€‚
    """
    with _db_lock, _get_db_connection() as conn:
        meta_count = conn.execute("SELECT COUNT(*) FROM meta").fetchone()[0]
        pending_count = conn.execute("SELECT COUNT(*) FROM pending_reminders").fetchone()[0]
        memory_count = conn.execute("SELECT COUNT(*) FROM short_term_memory").fetchone()[0]
        event_count = conn.execute("SELECT COUNT(*) FROM sys_events").fetchone()[0]

        if meta_count == 0 and os.path.exists(FILES["meta"]):
            meta = _load_json_file(FILES["meta"], default={}) or {}
            pinned_files = meta.get("pinned_files", [])
            conn.execute(
                "INSERT OR REPLACE INTO meta (user_id, key, value) VALUES (?, ?, ?)",
                (config.DEFAULT_USER_ID, "pinned_files", json.dumps(pinned_files, ensure_ascii=False))
            )
            logger.info("å·²è¿ç§» meta.json -> SQLite")

        if pending_count == 0 and os.path.exists(FILES["pending_reminders"]):
            reminders = _load_json_file(FILES["pending_reminders"], default=[]) or []
            rows = [
                (r.get("id"), config.DEFAULT_USER_ID, r.get("run_at", 0), r.get("prompt", ""))
                for r in reminders if r.get("id")
            ]
            if rows:
                conn.executemany(
                    "INSERT OR REPLACE INTO pending_reminders (id, user_id, run_at, prompt) VALUES (?, ?, ?, ?)",
                    rows
                )
            logger.info("å·²è¿ç§» pending_reminders.json -> SQLite")

        if memory_count == 0 and os.path.exists(FILES["short_term_memory"]):
            memory = _load_json_file(FILES["short_term_memory"], default=[]) or []
            rows = [
                (config.DEFAULT_USER_ID, m.get("role", "user"), m.get("text", ""), m.get("timestamp", 0))
                for m in memory
            ]
            if rows:
                conn.executemany(
                    "INSERT INTO short_term_memory (user_id, role, text, timestamp) VALUES (?, ?, ?, ?)",
                    rows
                )
            logger.info("å·²è¿ç§» short_term_memory.json -> SQLite")

        if event_count == 0 and os.path.exists(FILES["sys_bus"]):
            try:
                with open(FILES["sys_bus"], "r", encoding="utf-8") as f:
                    lines = f.readlines()
            except IOError as e:
                logger.warning(f"è¯»å– sys_event_bus å¤±è´¥: {e}")
                lines = []

            for line in lines:
                if not line.strip():
                    continue
                event_type = None
                event_id = None
                status = "pending"
                event_user_id = config.DEFAULT_USER_ID
                payload = line.strip()
                try:
                    event = json.loads(line)
                    event_type = event.get("type")
                    event_id = event.get("id") or event.get("reminder_id")
                    event_user_id = event.get("user_id") or config.DEFAULT_USER_ID
                    payload = json.dumps(event, ensure_ascii=False)
                except json.JSONDecodeError:
                    status = "invalid"
                conn.execute(
                    "INSERT INTO sys_events (user_id, event_id, event_type, payload, status, created_at) VALUES (?, ?, ?, ?, ?, ?)",
                    (event_user_id, event_id, event_type, payload, status, time.time())
                )
            if lines:
                logger.info("å·²è¿ç§» sys_event_bus.jsonl -> SQLite")

# --- ç”¨æˆ·æ˜ å°„ ---
def _create_user_id() -> str:
    return uuid.uuid4().hex


def lookup_user_id(platform: str, external_id: str) -> Optional[str]:
    platform = (platform or "").strip().lower()
    external_id = str(external_id or "").strip()
    if not platform or not external_id:
        return None
    try:
        with _db_lock, _get_db_connection() as conn:
            row = conn.execute(
                "SELECT user_id FROM user_mappings WHERE platform = ? AND external_id = ?",
                (platform, external_id)
            ).fetchone()
    except sqlite3.Error as e:
        logger.error(f"User mapping lookup failed: {e}")
        return None
    return row["user_id"] if row else None


def create_user(display_name: Optional[str] = None, user_id: Optional[str] = None) -> str:
    resolved_user_id = user_id or _create_user_id()
    now = time.time()
    try:
        with _db_lock, _get_db_connection() as conn:
            row = conn.execute(
                "SELECT user_id FROM users WHERE user_id = ?",
                (resolved_user_id,)
            ).fetchone()
            if not row:
                conn.execute(
                    "INSERT INTO users (user_id, display_name, created_at) VALUES (?, ?, ?)",
                    (resolved_user_id, display_name, now)
                )
            elif display_name:
                conn.execute(
                    "UPDATE users SET display_name = ? WHERE user_id = ?",
                    (display_name, resolved_user_id)
                )
    except sqlite3.Error as e:
        logger.error(f"Create user failed: {e}")
        return config.DEFAULT_USER_ID
    return resolved_user_id


def link_user_mapping(
    platform: str,
    external_id: str,
    user_id: str,
    display_name: Optional[str] = None,
    force: bool = False
) -> bool:
    platform = (platform or "").strip().lower()
    external_id = str(external_id or "").strip()
    if not platform or not external_id or not user_id:
        return False
    now = time.time()
    try:
        with _db_lock, _get_db_connection() as conn:
            row = conn.execute(
                "SELECT user_id FROM user_mappings WHERE platform = ? AND external_id = ?",
                (platform, external_id)
            ).fetchone()
            if row and row["user_id"] != user_id and not force:
                return False

            existing_user = conn.execute(
                "SELECT user_id FROM users WHERE user_id = ?",
                (user_id,)
            ).fetchone()
            if not existing_user:
                conn.execute(
                    "INSERT INTO users (user_id, display_name, created_at) VALUES (?, ?, ?)",
                    (user_id, display_name, now)
                )
            elif display_name:
                conn.execute(
                    "UPDATE users SET display_name = ? WHERE user_id = ?",
                    (display_name, user_id)
                )

            if row:
                conn.execute(
                    "UPDATE user_mappings SET user_id = ? WHERE platform = ? AND external_id = ?",
                    (user_id, platform, external_id)
                )
            else:
                conn.execute(
                    "INSERT INTO user_mappings (platform, external_id, user_id, created_at) VALUES (?, ?, ?, ?)",
                    (platform, external_id, user_id, now)
                )
    except sqlite3.Error as e:
        logger.error(f"Link user mapping failed: {e}")
        return False
    return True


def list_users() -> list[dict]:
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT user_id, display_name, created_at FROM users ORDER BY created_at"
            ).fetchall()
    except sqlite3.Error as e:
        logger.error(f"List users failed: {e}")
        return []
    return [
        {
            "user_id": row["user_id"],
            "display_name": row["display_name"],
            "created_at": row["created_at"],
        }
        for row in rows
    ]


def list_user_mappings(platform: Optional[str] = None) -> list[dict]:
    platform = (platform or "").strip().lower()
    try:
        with _db_lock, _get_db_connection() as conn:
            if platform:
                rows = conn.execute(
                    "SELECT platform, external_id, user_id, created_at FROM user_mappings WHERE platform = ?",
                    (platform,)
                ).fetchall()
            else:
                rows = conn.execute(
                    "SELECT platform, external_id, user_id, created_at FROM user_mappings"
                ).fetchall()
    except sqlite3.Error as e:
        logger.error(f"List user mappings failed: {e}")
        return []
    return [
        {
            "platform": row["platform"],
            "external_id": row["external_id"],
            "user_id": row["user_id"],
            "created_at": row["created_at"],
        }
        for row in rows
    ]


def resolve_user_id(platform: str, external_id: str, display_name: Optional[str] = None) -> str:
    """
    è·å–æˆ–åˆ›å»ºå†…éƒ¨ user_idã€‚
    platform: ä¾‹å¦‚ "telegram"
    external_id: å¹³å°ä¾§ç”¨æˆ·æ ‡è¯†ï¼ˆå¦‚ chat_idï¼‰
    """
    platform = (platform or "").strip().lower()
    external_id = str(external_id or "").strip()
    if not platform or not external_id:
        return config.DEFAULT_USER_ID

    with _db_lock, _get_db_connection() as conn:
        try:
            row = conn.execute(
                "SELECT user_id FROM user_mappings WHERE platform = ? AND external_id = ?",
                (platform, external_id)
            ).fetchone()
            if row:
                user_id = row["user_id"]
                if display_name:
                    conn.execute(
                        "UPDATE users SET display_name = ? WHERE user_id = ?",
                        (display_name, user_id)
                    )
                return user_id

            user_id = _create_user_id()
            now = time.time()
            conn.execute(
                "INSERT INTO users (user_id, display_name, created_at) VALUES (?, ?, ?)",
                (user_id, display_name, now)
            )
            conn.execute(
                "INSERT INTO user_mappings (platform, external_id, user_id, created_at) VALUES (?, ?, ?, ?)",
                (platform, external_id, user_id, now)
            )
            logger.info("å·²åˆ›å»ºæ–°ç”¨æˆ·æ˜ å°„ platform=%s external_id=%s user_id=%s", platform, external_id, user_id)
            return user_id
        except sqlite3.Error as e:
            logger.error(f"ç”¨æˆ·æ˜ å°„å¤±è´¥: {e}")
            return config.DEFAULT_USER_ID


def get_external_id(user_id: str, platform: str) -> Optional[str]:
    platform = (platform or "").strip().lower()
    if not platform or not user_id:
        return None
    try:
        with _db_lock, _get_db_connection() as conn:
            row = conn.execute(
                "SELECT external_id FROM user_mappings WHERE platform = ? AND user_id = ?",
                (platform, user_id)
            ).fetchone()
    except sqlite3.Error as e:
        logger.error(f"è¯»å–ç”¨æˆ·æ˜ å°„å¤±è´¥: {e}")
        return None
    return row["external_id"] if row else None

# --- é€šç”¨æ–‡ä»¶è¯»å†™ ---
def _load_meta(default: Optional[Any] = None, user_id: Optional[str] = None) -> Any:
    resolved_user_id = user_id or get_current_user_id()
    fallback = default if default is not None else {"pinned_files": []}
    try:
        with _db_lock, _get_db_connection() as conn:
            row = conn.execute(
                "SELECT value FROM meta WHERE user_id = ? AND key = ?",
                (resolved_user_id, "pinned_files")
            ).fetchone()
    except sqlite3.Error as e:
        logger.error(f"è¯»å– meta å¤±è´¥: {e}")
        return fallback
    if not row:
        return fallback
    try:
        pinned_files = json.loads(row["value"]) if row["value"] else []
    except json.JSONDecodeError as e:
        logger.warning(f"meta è§£æå¤±è´¥: {e}")
        return fallback
    return {"pinned_files": pinned_files}


def _save_meta(data: Any, user_id: Optional[str] = None) -> bool:
    if not isinstance(data, dict):
        logger.error("meta ä¿å­˜å¤±è´¥ï¼šæ•°æ®ç»“æ„ä¸æ˜¯ dict")
        return False
    pinned_files = data.get("pinned_files", [])
    try:
        value = json.dumps(pinned_files, ensure_ascii=False)
    except TypeError as e:
        logger.error(f"meta åºåˆ—åŒ–å¤±è´¥: {e}")
        return False
    resolved_user_id = user_id or get_current_user_id()
    try:
        with _db_lock, _get_db_connection() as conn:
            conn.execute(
                "INSERT OR REPLACE INTO meta (user_id, key, value) VALUES (?, ?, ?)",
                (resolved_user_id, "pinned_files", value)
            )
        return True
    except sqlite3.Error as e:
        logger.error(f"ä¿å­˜ meta å¤±è´¥: {e}")
        return False


def _load_pending_reminders(default: Optional[Any] = None, user_id: Optional[str] = None) -> Any:
    resolved_user_id = user_id or get_current_user_id()
    fallback = default if default is not None else []
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT id, run_at, prompt FROM pending_reminders WHERE user_id = ? ORDER BY run_at",
                (resolved_user_id,)
            ).fetchall()
    except sqlite3.Error as e:
        logger.error(f"è¯»å– pending_reminders å¤±è´¥: {e}")
        return fallback
    if not rows:
        return fallback
    return [{"id": r["id"], "run_at": r["run_at"], "prompt": r["prompt"]} for r in rows]


def _save_pending_reminders(data: Any, user_id: Optional[str] = None) -> bool:
    if not isinstance(data, list):
        logger.error("pending_reminders ä¿å­˜å¤±è´¥ï¼šæ•°æ®ç»“æ„ä¸æ˜¯ list")
        return False
    resolved_user_id = user_id or get_current_user_id()
    rows = [
        (r.get("id"), resolved_user_id, r.get("run_at", 0), r.get("prompt", ""))
        for r in data if r.get("id")
    ]
    try:
        with _db_lock, _get_db_connection() as conn:
            conn.execute("DELETE FROM pending_reminders WHERE user_id = ?", (resolved_user_id,))
            if rows:
                conn.executemany(
                    "INSERT OR REPLACE INTO pending_reminders (id, user_id, run_at, prompt) VALUES (?, ?, ?, ?)",
                    rows
                )
        return True
    except sqlite3.Error as e:
        logger.error(f"ä¿å­˜ pending_reminders å¤±è´¥: {e}")
        return False


def _load_short_term_memory(default: Optional[Any] = None, user_id: Optional[str] = None) -> Any:
    resolved_user_id = user_id or get_current_user_id()
    fallback = default if default is not None else []
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT role, text, timestamp FROM short_term_memory WHERE user_id = ? ORDER BY id",
                (resolved_user_id,)
            ).fetchall()
    except sqlite3.Error as e:
        logger.error(f"è¯»å– short_term_memory å¤±è´¥: {e}")
        return fallback
    if not rows:
        return fallback
    return [{"role": r["role"], "text": r["text"], "timestamp": r["timestamp"]} for r in rows]


def _save_short_term_memory(data: Any, user_id: Optional[str] = None) -> bool:
    if not isinstance(data, list):
        logger.error("short_term_memory ä¿å­˜å¤±è´¥ï¼šæ•°æ®ç»“æ„ä¸æ˜¯ list")
        return False
    resolved_user_id = user_id or get_current_user_id()
    rows = [
        (resolved_user_id, m.get("role", "user"), m.get("text", ""), m.get("timestamp", 0))
        for m in data
    ]
    try:
        with _db_lock, _get_db_connection() as conn:
            conn.execute("DELETE FROM short_term_memory WHERE user_id = ?", (resolved_user_id,))
            if rows:
                conn.executemany(
                    "INSERT INTO short_term_memory (user_id, role, text, timestamp) VALUES (?, ?, ?, ?)",
                    rows
                )
        return True
    except sqlite3.Error as e:
        logger.error(f"ä¿å­˜ short_term_memory å¤±è´¥: {e}")
        return False


def load_all_pending_reminders() -> list[dict]:
    """è¯»å–æ‰€æœ‰ç”¨æˆ·çš„ pending_remindersï¼ˆä¾›æ¢å¤ä»»åŠ¡ä½¿ç”¨ï¼‰ã€‚"""
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT id, user_id, run_at, prompt FROM pending_reminders ORDER BY run_at"
            ).fetchall()
    except sqlite3.Error as e:
        logger.error(f"è¯»å–å…¨éƒ¨ pending_reminders å¤±è´¥: {e}")
        return []
    return [
        {"id": r["id"], "user_id": r["user_id"], "run_at": r["run_at"], "prompt": r["prompt"]}
        for r in rows
    ]

def load_json(file_key: str, default: Optional[Any] = None, user_id: Optional[str] = None) -> Any:
    """è¯»å–æŒ‡å®šçš„ JSON æ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    if file_key == "meta":
        return _load_meta(default, user_id)
    if file_key == "pending_reminders":
        return _load_pending_reminders(default, user_id)
    if file_key == "short_term_memory":
        return _load_short_term_memory(default, user_id)

    path = FILES.get(file_key)
    if not path or not os.path.exists(path):
        return default if default is not None else []

    lock = _get_file_lock(path)
    with lock:
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æå¤±è´¥ {path}: {e}")
            return default if default is not None else []
        except IOError as e:
            logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {path}: {e}")
            return default if default is not None else []

def save_json(file_key: str, data: Any, user_id: Optional[str] = None) -> bool:
    """ä¿å­˜æ•°æ®åˆ°æŒ‡å®šçš„ JSON æ–‡ä»¶ï¼ˆåŸå­æ€§å†™å…¥ï¼Œçº¿ç¨‹å®‰å…¨ï¼‰"""
    if file_key == "meta":
        return _save_meta(data, user_id)
    if file_key == "pending_reminders":
        return _save_pending_reminders(data, user_id)
    if file_key == "short_term_memory":
        return _save_short_term_memory(data, user_id)

    path = FILES.get(file_key)
    if not path:
        logger.error(f"æœªçŸ¥çš„ file_key: {file_key}")
        return False

    lock = _get_file_lock(path)
    temp_path = path + ".tmp"

    with lock:
        try:
            with open(temp_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            # åŸå­æ€§æ›¿æ¢ï¼ˆWindows éœ€è¦å…ˆåˆ é™¤ç›®æ ‡æ–‡ä»¶ï¼‰
            if os.path.exists(path):
                os.replace(temp_path, path)
            else:
                os.rename(temp_path, path)
            return True
        except IOError as e:
            logger.error(f"ä¿å­˜ {path} å¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except OSError:
                    pass
            return False
        except TypeError as e:
            logger.error(f"JSON åºåˆ—åŒ–å¤±è´¥ {path}: {e}")
            if os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except OSError:
                    pass
            return False

# --- Amaya è®°å¿†æ–‡ä»¶ç³»ç»Ÿ API ---
def _safe_user_id(user_id: str) -> str:
    return re.sub(r"[^a-zA-Z0-9_-]", "_", user_id or config.DEFAULT_USER_ID)


def _migrate_legacy_default_memory_dir() -> None:
    global _legacy_memory_migrated
    if _legacy_memory_migrated:
        return
    _legacy_memory_migrated = True

    default_dir = os.path.join(DATA_DIR, _safe_user_id(config.DEFAULT_USER_ID))
    os.makedirs(default_dir, exist_ok=True)
    try:
        legacy_files = [
            name for name in os.listdir(DATA_DIR)
            if not name.startswith(".") and os.path.isfile(os.path.join(DATA_DIR, name))
        ]
    except OSError:
        return

    if not legacy_files:
        return

    try:
        existing_files = {
            name for name in os.listdir(default_dir)
            if not name.startswith(".") and os.path.isfile(os.path.join(default_dir, name))
        }
    except OSError:
        existing_files = set()

    for name in legacy_files:
        src = os.path.join(DATA_DIR, name)
        dst = os.path.join(default_dir, name)
        if name in existing_files:
            logger.warning("Skip legacy memory file due to conflict: %s", name)
            continue
        try:
            os.replace(src, dst)
            logger.info("Migrated legacy memory file to default user dir: %s", name)
        except OSError as e:
            logger.warning("Failed to migrate legacy memory file %s: %s", name, e)


def _get_user_memory_dir(user_id: Optional[str] = None) -> str:
    resolved_user_id = _safe_user_id(user_id or get_current_user_id())
    if resolved_user_id == _safe_user_id(config.DEFAULT_USER_ID):
        _migrate_legacy_default_memory_dir()
    path = os.path.join(DATA_DIR, resolved_user_id)
    os.makedirs(path, exist_ok=True)
    return path


def list_files_in_memory(user_id: Optional[str] = None) -> List[str]:
    """åˆ—å‡ºæ‰€æœ‰è®°å¿†æ–‡ä»¶"""
    try:
        dir_path = _get_user_memory_dir(user_id)
        return [f for f in os.listdir(dir_path) if not f.startswith('.')]
    except OSError as e:
        logger.error(f"åˆ—å‡ºè®°å¿†æ–‡ä»¶å¤±è´¥: {e}")
        return []

def read_file_content(filename: str, user_id: Optional[str] = None) -> Optional[str]:
    """è¯»å–è®°å¿†åº“ä¸­çš„æ–‡ä»¶å†…å®¹"""
    dir_path = _get_user_memory_dir(user_id)
    path = os.path.join(dir_path, os.path.basename(filename)) # å®‰å…¨å¤„ç†
    if not os.path.exists(path):
        return None
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    except IOError as e:
        logger.error(f"è¯»å–æ–‡ä»¶ {filename} å¤±è´¥: {e}")
        return None
    except Exception as e:
        logger.exception(f"è¯»å–æ–‡ä»¶ {filename} å¼‚å¸¸: {e}")
        return None

def write_file_content(filename: str, content: str, user_id: Optional[str] = None) -> bool:
    """å†™å…¥/è¦†ç›–è®°å¿†åº“ä¸­çš„æ–‡ä»¶å†…å®¹"""
    dir_path = _get_user_memory_dir(user_id)
    path = os.path.join(dir_path, os.path.basename(filename))
    try:
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        logger.debug(f"å·²å†™å…¥æ–‡ä»¶: {filename}")
        return True
    except IOError as e:
        logger.error(f"å†™å…¥æ–‡ä»¶ {filename} å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.exception(f"å†™å…¥æ–‡ä»¶ {filename} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return False

def delete_file(filename, user_id: Optional[str] = None):
    """åˆ é™¤è®°å¿†åº“ä¸­çš„æ–‡ä»¶"""
    dir_path = _get_user_memory_dir(user_id)
    path = os.path.join(dir_path, os.path.basename(filename))
    if os.path.exists(path):
        os.remove(path)
        toggle_pin_status(filename, pin=False, user_id=user_id)
        return True
    return False

# --- ç½®é¡¶ (Pin) é€»è¾‘ ---
def toggle_pin_status(filename, pin: bool, user_id: Optional[str] = None):
    """è®¾ç½®æˆ–å–æ¶ˆç½®é¡¶"""
    meta = load_json("meta", default={"pinned_files": []}, user_id=user_id)
    safe_name = os.path.basename(filename)
    if pin:
        if safe_name not in meta["pinned_files"]:
            meta["pinned_files"].append(safe_name)
    else:
        if safe_name in meta["pinned_files"]:
            meta["pinned_files"].remove(safe_name)
    save_json("meta", meta, user_id=user_id)
    return safe_name in meta["pinned_files"]

def get_pinned_content(user_id: Optional[str] = None):
    """è·å–æ‰€æœ‰ç½®é¡¶æ–‡ä»¶çš„å†…å®¹"""
    meta = load_json("meta", default={"pinned_files": []}, user_id=user_id)
    context_str = ""
    for fname in meta["pinned_files"]:
        content = read_file_content(fname, user_id=user_id)
        if content:
            context_str += f"\n--- [Pinned Memory: {fname}] ---\n{content}\n"
    return context_str



def get_pending_reminders_summary(user_id: Optional[str] = None):
    """å°†æŒ‚èµ·çš„é—¹é’Ÿä»»åŠ¡è½¬æ¢ä¸ºè¾ƒä¸ºå¯è¯»çš„æ‘˜è¦"""
    reminders = load_json("pending_reminders", default=[], user_id=user_id)
    if not reminders:
        return "æ— æŒ‚èµ·çš„æé†’ä»»åŠ¡ã€‚"

    summary = []
    now = time.time()
    for reminder in reminders:
        reminder_id = reminder.get('id', '')
        run_at = reminder.get('run_at', 0)
        prompt = reminder.get('prompt', 'æœªçŸ¥ä»»åŠ¡')

        # è®¡ç®—å‰©ä½™æ—¶é—´
        diff = int(run_at - now)
        if diff > 0:
            time_str = f"{diff}ç§’å"
            # å¦‚æœæ—¶é—´å¾ˆé•¿ï¼Œæ˜¾ç¤ºå…·ä½“æ—¥æœŸ
            if diff > 3600:
                dt = datetime.fromtimestamp(run_at)
                time_str = dt.strftime("%m-%d %H:%M")
            summary.append(f"- (ID: {reminder_id}) {prompt} (æ‰§è¡Œæ—¶é—´: {time_str})")

    if not summary:
        return "æ— æŒ‚èµ·çš„æé†’ä»»åŠ¡ã€‚"
    return "ä»¥ä¸‹æ˜¯æé†’ä»»åŠ¡åˆ—è¡¨\n" + "\n".join(summary)

def get_global_context_string(user_id: Optional[str] = None):
    """
    ã€æ ¸å¿ƒå‡½æ•°ã€‘
    èšåˆæ‰€æœ‰ Amaya éœ€è¦"é»˜è®¤"çœ‹è§çš„ä¿¡æ¯ã€‚
    åŒ…æ‹¬ï¼š
    1. Pinned Files (ç”¨æˆ·æ‰‹åŠ¨ç½®é¡¶)
    2. Default Files (ç³»ç»Ÿé»˜è®¤å¯è§ï¼Œå¦‚ routine.md)
    3. Pending Reminders (å½“å‰çš„æé†’åˆ—è¡¨)
    4. etc
    """
    context_parts = []
    resolved_user_id = user_id or get_current_user_id()

    # 1. è·å– Pinned Files
    meta = load_json("meta", default={"pinned_files": []}, user_id=resolved_user_id)
    pinned_set = set(meta.get("pinned_files", []))

    # 2. åˆå¹¶ Default Files (å»é‡)
    dir_path = _get_user_memory_dir(resolved_user_id)
    for f in config.DEFAULT_VISIBLE_FILES:
        if os.path.exists(os.path.join(dir_path, f)):
            pinned_set.add(f)

    # 3. è¯»å–å¹¶ç»„è£…å†…å®¹
    if pinned_set:
        context_parts.append("=== ğŸ“‚ MEMORY BANK (ACTIVE FILES) ===")
        for fname in pinned_set:
            content = read_file_content(fname, user_id=resolved_user_id)
            if content:
                # åŠ ä¸Šæ–‡ä»¶åä½œä¸ºæ ‡é¢˜ï¼Œæ–¹ä¾¿ AI åŒºåˆ†
                context_parts.append(f"\n--- FILE: {fname} ---\n{content}")

    # 4. æ³¨å…¥ Pending Reminders (è¿™èƒ½æœ‰æ•ˆé˜²æ­¢é‡å¤è®¾ç½®æé†’ï¼)
    reminders_summary = get_pending_reminders_summary(user_id=resolved_user_id)
    context_parts.append(f"\n=== ACTIVE TIMERS (PENDING) ===\n{reminders_summary}")

    full_context = "\n".join(context_parts)
    if len(full_context) > config.GLOBAL_CONTEXT_MAX_CHARS:
        truncated = full_context[:config.GLOBAL_CONTEXT_MAX_CHARS]
        notice = f"[Context trimmed to {config.GLOBAL_CONTEXT_MAX_CHARS} chars]\n"
        return notice + truncated
    return full_context


# --- äº‹ä»¶æ€»çº¿è¯»å†™ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰---
def append_event_to_bus(event: dict, user_id: Optional[str] = None) -> bool:
    """
    çº¿ç¨‹å®‰å…¨åœ°å‘ç³»ç»Ÿäº‹ä»¶æ€»çº¿è¿½åŠ ä¸€æ¡äº‹ä»¶ã€‚
    """
    resolved_user_id = user_id or get_current_user_id()
    if "user_id" not in event:
        event["user_id"] = resolved_user_id
    try:
        payload = json.dumps(event, ensure_ascii=False)
    except TypeError as e:
        logger.error(f"äº‹ä»¶åºåˆ—åŒ–å¤±è´¥: {e}")
        return False

    event_id = event.get("id") or event.get("reminder_id") or "-"
    event_type = event.get("type")
    resolved_user_id = event.get("user_id") or resolved_user_id
    try:
        with _db_lock, _get_db_connection() as conn:
            conn.execute(
                "INSERT INTO sys_events (user_id, event_id, event_type, payload, status, created_at) VALUES (?, ?, ?, ?, ?, ?)",
                (resolved_user_id, event_id, event_type, payload, "pending", time.time())
            )
    except sqlite3.Error as e:
        event_logger.error(f"äº‹ä»¶æ€»çº¿å†™å…¥å¤±è´¥: {e}")
        return False
    event_logger.debug("äº‹ä»¶å†™å…¥æ€»çº¿ type=%s id=%s", event_type, event_id)
    return True


def read_events_from_bus() -> tuple[list[dict], list[str]]:
    """
    çº¿ç¨‹å®‰å…¨åœ°è¯»å–å¹¶æ¸…ç©ºç³»ç»Ÿäº‹ä»¶æ€»çº¿ã€‚
    è¿”å› (events, invalid_lines)ã€‚
    """
    events: list[dict] = []
    invalid_lines: list[str] = []
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT id, payload, user_id FROM sys_events WHERE status = 'pending' ORDER BY id"
            ).fetchall()
            if not rows:
                return [], []

            valid_ids: list[int] = []
            invalid_ids: list[int] = []

            for row in rows:
                payload = row["payload"]
                row_user_id = row["user_id"]
                try:
                    event = json.loads(payload)
                    if isinstance(event, dict) and "user_id" not in event:
                        event["user_id"] = row_user_id or config.DEFAULT_USER_ID
                    events.append(event)
                    valid_ids.append(row["id"])
                except json.JSONDecodeError as e:
                    event_logger.warning(f"äº‹ä»¶è§£æå¤±è´¥: {e}")
                    invalid_lines.append(payload)
                    invalid_ids.append(row["id"])

            now = time.time()
            if valid_ids:
                placeholders = ",".join(["?"] * len(valid_ids))
                conn.execute(
                    f"UPDATE sys_events SET status = 'processed', processed_at = ? WHERE id IN ({placeholders})",
                    [now, *valid_ids]
                )
            if invalid_ids:
                placeholders = ",".join(["?"] * len(invalid_ids))
                conn.execute(
                    f"UPDATE sys_events SET status = 'invalid', processed_at = ? WHERE id IN ({placeholders})",
                    [now, *invalid_ids]
                )
    except sqlite3.Error as e:
        event_logger.error(f"è¯»å–äº‹ä»¶æ€»çº¿å¤±è´¥: {e}")
        return [], []

    event_logger.debug("äº‹ä»¶æ€»çº¿è¯»å–å®Œæˆ events=%s invalid=%s", len(events), len(invalid_lines))
    return events, invalid_lines


_init_db()
