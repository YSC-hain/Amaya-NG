# utils/storage.py
import json
import os
import logging
import sqlite3
import re
from datetime import datetime, timedelta, date
import time
from typing import Any, Optional, List
import config
from utils.user_context import get_current_user_id
from utils.db import get_db_connection, get_db_lock, DB_PATH
# ç”¨æˆ·ç®¡ç†å‡½æ•°ï¼ˆä» user_storage å¯¼å…¥å¹¶é‡æ–°å¯¼å‡ºï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
from utils.user_storage import (
    lookup_user_id,
    create_user,
    link_user_mapping,
    list_users,
    list_user_mappings,
    resolve_user_id,
    get_external_id,
)
# è®°å¿†æ–‡ä»¶ç³»ç»Ÿå‡½æ•°ï¼ˆä» memory_storage å¯¼å…¥å¹¶é‡æ–°å¯¼å‡ºï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
from utils.memory_storage import (
    get_user_memory_dir as _get_user_memory_dir,
    list_files_in_memory,
    read_file_content,
    write_file_content,
    delete_file as _delete_file_impl,
    _safe_user_id,
    DATA_DIR,
)

logger = logging.getLogger("Amaya.Storage")
event_logger = logging.getLogger("Amaya.EventBus")

# å…¼å®¹æ—§ä»£ç çš„åˆ«å
_db_lock = get_db_lock()
_get_db_connection = get_db_connection


def build_reminder_id(run_at: float) -> str:
    """åŸºäºæ—¶é—´æˆ³å’Œéšæœºç†µç”ŸæˆçŸ­ IDï¼Œé¿å…åŒç§’å†²çªã€‚"""
    import secrets
    ts_part = format(int(run_at * 1000), 'x')[-8:]
    rand_part = secrets.token_hex(3)
    return f"r{ts_part}{rand_part}"


# å®šä¹‰è®°å¿†åº“çš„ç‰©ç†è·¯å¾„
DATA_DIR = "data/memory_bank"
os.makedirs(DATA_DIR, exist_ok=True)
SCHEDULE_FILE = "routine.json"

# æ³¨æ„ï¼šæ•°æ®åº“åˆå§‹åŒ–å·²ç§»è‡³ utils/db.pyï¼Œå¯¼å…¥æ—¶è‡ªåŠ¨å®Œæˆ
# æ³¨æ„ï¼šç”¨æˆ·ç®¡ç†å‡½æ•°å·²ç§»è‡³ utils/user_storage.pyï¼Œé€šè¿‡é¡¶éƒ¨å¯¼å…¥é‡æ–°å¯¼å‡º

# --- é€šç”¨æ–‡ä»¶è¯»å†™ ---
def _load_meta(default: Optional[Any] = None, user_id: Optional[str] = None) -> Any:
    resolved_user_id = user_id or get_current_user_id()
    fallback = default if default is not None else {"pinned_files": []}
    try:
        with _db_lock, _get_db_connection() as conn:
            row = conn.execute(
                "SELECT value FROM meta WHERE user_id = ? AND key = ?",
                (resolved_user_id, "pinned_files")
            ).fetchone()
    except sqlite3.Error as e:
        logger.error(f"è¯»å– meta å¤±è´¥: {e}")
        return fallback
    if not row:
        return fallback
    try:
        pinned_files = json.loads(row["value"]) if row["value"] else []
    except json.JSONDecodeError as e:
        logger.warning(f"meta è§£æå¤±è´¥: {e}")
        return fallback
    return {"pinned_files": pinned_files}


def _save_meta(data: Any, user_id: Optional[str] = None) -> bool:
    if not isinstance(data, dict):
        logger.error("meta ä¿å­˜å¤±è´¥ï¼šæ•°æ®ç»“æ„ä¸æ˜¯ dict")
        return False
    pinned_files = data.get("pinned_files", [])
    try:
        value = json.dumps(pinned_files, ensure_ascii=False)
    except TypeError as e:
        logger.error(f"meta åºåˆ—åŒ–å¤±è´¥: {e}")
        return False
    resolved_user_id = user_id or get_current_user_id()
    try:
        with _db_lock, _get_db_connection() as conn:
            conn.execute(
                "INSERT OR REPLACE INTO meta (user_id, key, value) VALUES (?, ?, ?)",
                (resolved_user_id, "pinned_files", value)
            )
        return True
    except sqlite3.Error as e:
        logger.error(f"ä¿å­˜ meta å¤±è´¥: {e}")
        return False


def _load_pending_reminders(default: Optional[Any] = None, user_id: Optional[str] = None) -> Any:
    resolved_user_id = user_id or get_current_user_id()
    fallback = default if default is not None else []
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT id, run_at, prompt FROM pending_reminders WHERE user_id = ? ORDER BY run_at",
                (resolved_user_id,)
            ).fetchall()
    except sqlite3.Error as e:
        logger.error(f"è¯»å– pending_reminders å¤±è´¥: {e}")
        return fallback
    if not rows:
        return fallback
    return [{"id": r["id"], "run_at": r["run_at"], "prompt": r["prompt"]} for r in rows]


def _save_pending_reminders(data: Any, user_id: Optional[str] = None) -> bool:
    if not isinstance(data, list):
        logger.error("pending_reminders ä¿å­˜å¤±è´¥ï¼šæ•°æ®ç»“æ„ä¸æ˜¯ list")
        return False
    resolved_user_id = user_id or get_current_user_id()
    rows = [
        (r.get("id"), resolved_user_id, r.get("run_at", 0), r.get("prompt", ""))
        for r in data if r.get("id")
    ]
    try:
        with _db_lock, _get_db_connection() as conn:
            conn.execute("DELETE FROM pending_reminders WHERE user_id = ?", (resolved_user_id,))
            if rows:
                conn.executemany(
                    "INSERT OR REPLACE INTO pending_reminders (id, user_id, run_at, prompt) VALUES (?, ?, ?, ?)",
                    rows
                )
        return True
    except sqlite3.Error as e:
        logger.error(f"ä¿å­˜ pending_reminders å¤±è´¥: {e}")
        return False


def _load_short_term_memory(default: Optional[Any] = None, user_id: Optional[str] = None) -> Any:
    resolved_user_id = user_id or get_current_user_id()
    fallback = default if default is not None else []
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT role, text, timestamp FROM short_term_memory WHERE user_id = ? ORDER BY id",
                (resolved_user_id,)
            ).fetchall()
    except sqlite3.Error as e:
        logger.error(f"è¯»å– short_term_memory å¤±è´¥: {e}")
        return fallback
    if not rows:
        return fallback
    return [{"role": r["role"], "text": r["text"], "timestamp": r["timestamp"]} for r in rows]


def _save_short_term_memory(data: Any, user_id: Optional[str] = None) -> bool:
    if not isinstance(data, list):
        logger.error("short_term_memory ä¿å­˜å¤±è´¥ï¼šæ•°æ®ç»“æ„ä¸æ˜¯ list")
        return False
    resolved_user_id = user_id or get_current_user_id()
    rows = [
        (resolved_user_id, m.get("role", "user"), m.get("text", ""), m.get("timestamp", 0))
        for m in data
    ]
    try:
        with _db_lock, _get_db_connection() as conn:
            conn.execute("DELETE FROM short_term_memory WHERE user_id = ?", (resolved_user_id,))
            if rows:
                conn.executemany(
                    "INSERT INTO short_term_memory (user_id, role, text, timestamp) VALUES (?, ?, ?, ?)",
                    rows
                )
        return True
    except sqlite3.Error as e:
        logger.error(f"ä¿å­˜ short_term_memory å¤±è´¥: {e}")
        return False


def load_all_pending_reminders() -> list[dict]:
    """è¯»å–æ‰€æœ‰ç”¨æˆ·çš„ pending_remindersï¼ˆä¾›æ¢å¤ä»»åŠ¡ä½¿ç”¨ï¼‰ã€‚"""
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT id, user_id, run_at, prompt FROM pending_reminders ORDER BY run_at"
            ).fetchall()
    except sqlite3.Error as e:
        logger.error(f"è¯»å–å…¨éƒ¨ pending_reminders å¤±è´¥: {e}")
        return []
    return [
        {"id": r["id"], "user_id": r["user_id"], "run_at": r["run_at"], "prompt": r["prompt"]}
        for r in rows
    ]

def load_json(file_key: str, default: Optional[Any] = None, user_id: Optional[str] = None) -> Any:
    """è¯»å–æŒ‡å®šçš„ JSON æ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    if file_key == "meta":
        return _load_meta(default, user_id)
    if file_key == "pending_reminders":
        return _load_pending_reminders(default, user_id)
    if file_key == "short_term_memory":
        return _load_short_term_memory(default, user_id)
    logger.error(f"æœªçŸ¥çš„ file_key: {file_key}")
    return default if default is not None else []

def save_json(file_key: str, data: Any, user_id: Optional[str] = None) -> bool:
    """ä¿å­˜æ•°æ®åˆ°æŒ‡å®šçš„ JSON æ•°æ®ï¼ˆåŸå­æ€§å†™å…¥ï¼Œçº¿ç¨‹å®‰å…¨ï¼‰"""
    if file_key == "meta":
        return _save_meta(data, user_id)
    if file_key == "pending_reminders":
        return _save_pending_reminders(data, user_id)
    if file_key == "short_term_memory":
        return _save_short_term_memory(data, user_id)
    logger.error(f"æœªçŸ¥çš„ file_key: {file_key}")
    return False

# æ³¨æ„ï¼šè®°å¿†æ–‡ä»¶ç³»ç»Ÿå‡½æ•° (list_files_in_memory, read_file_content, write_file_content)
# å·²ç§»è‡³ utils/memory_storage.pyï¼Œé€šè¿‡é¡¶éƒ¨å¯¼å…¥é‡æ–°å¯¼å‡º

# --- æ—¥ç¨‹è¡¨å­˜å‚¨ ---
SCHEDULE_FILE = "routine.json"


def _default_schedule() -> dict:
    return {
        "version": 1,
        "timezone": config.TIMEZONE,
        "days": [],
        "updated_at": datetime.now().isoformat(timespec="seconds")
    }


def build_schedule_item_id(existing_ids: Optional[set[str]] = None) -> str:
    import secrets
    existing_ids = existing_ids or set()
    while True:
        candidate = f"e{int(time.time() * 1000):x}{secrets.token_hex(2)}"
        if candidate not in existing_ids:
            return candidate


def _normalize_schedule(data: Any) -> dict:
    schedule = _default_schedule()
    if not isinstance(data, dict):
        return schedule

    timezone = data.get("timezone") or schedule["timezone"]
    schedule["timezone"] = timezone
    schedule["version"] = data.get("version", schedule["version"])

    days = data.get("days", [])
    if not isinstance(days, list):
        return schedule

    normalized_days = []
    for day in days:
        if not isinstance(day, dict):
            continue
        date_str = str(day.get("date", "")).strip()
        if not date_str:
            continue
        items = day.get("items", [])
        if not isinstance(items, list):
            items = []
        normalized_items = []
        existing_ids: set[str] = set()
        for item in items:
            if not isinstance(item, dict):
                continue
            title = str(item.get("title", "")).strip()
            if not title:
                continue
            item_id = str(item.get("id") or build_schedule_item_id(existing_ids))
            existing_ids.add(item_id)
            tags = item.get("tags", [])
            if not isinstance(tags, list):
                tags = []
            normalized_items.append({
                "id": item_id,
                "start": str(item.get("start", "")).strip(),
                "end": str(item.get("end", "")).strip(),
                "title": title,
                "location": str(item.get("location", "")).strip(),
                "note": str(item.get("note", "")).strip(),
                "tags": tags
            })
        normalized_days.append({"date": date_str, "items": normalized_items})

    schedule["days"] = sorted(normalized_days, key=lambda d: d.get("date", ""))
    return schedule


def load_schedule(user_id: Optional[str] = None) -> dict:
    content = read_file_content(SCHEDULE_FILE, user_id=user_id)
    if not content:
        return _default_schedule()
    try:
        data = json.loads(content)
    except json.JSONDecodeError as e:
        logger.warning(f"{SCHEDULE_FILE} è§£æå¤±è´¥: {e}")
        return _default_schedule()
    return _normalize_schedule(data)


def save_schedule(schedule: dict, user_id: Optional[str] = None) -> bool:
    if not isinstance(schedule, dict):
        logger.error(f"{SCHEDULE_FILE} ä¿å­˜å¤±è´¥ï¼šæ•°æ®ç»“æ„ä¸æ˜¯ dict")
        return False
    normalized = _normalize_schedule(schedule)
    normalized["updated_at"] = datetime.now().isoformat(timespec="seconds")
    try:
        content = json.dumps(normalized, ensure_ascii=False, indent=2)
    except TypeError as e:
        logger.error(f"{SCHEDULE_FILE} åºåˆ—åŒ–å¤±è´¥: {e}")
        return False
    return write_file_content(SCHEDULE_FILE, content, user_id=user_id)


def _parse_schedule_date(date_str: str) -> Optional[date]:
    try:
        return datetime.strptime(date_str, "%Y-%m-%d").date()
    except (TypeError, ValueError):
        return None


def _time_to_minutes(time_str: str) -> Optional[int]:
    if not time_str:
        return None
    try:
        value = datetime.strptime(time_str, "%H:%M")
    except (TypeError, ValueError):
        return None
    return value.hour * 60 + value.minute


# åˆ«åï¼Œä¾› tools.py ä½¿ç”¨ç»Ÿä¸€å‘½å
_parse_schedule_time = _time_to_minutes


def _sort_schedule_items(items: list[dict]) -> list[dict]:
    def _key(item: dict) -> tuple:
        start = _time_to_minutes(item.get("start", ""))
        return (start if start is not None else 24 * 60 + 1, item.get("title", ""))
    return sorted(items, key=_key)


def _format_schedule_item(item: dict) -> str:
    parts = []
    start = item.get("start", "")
    end = item.get("end", "")
    title = item.get("title", "")
    if start and end:
        parts.append(f"{start}-{end}")
    elif start:
        parts.append(start)
    if title:
        parts.append(title)
    line = " ".join(parts) if parts else title
    location = item.get("location", "")
    if location:
        line += f" @ {location}"
    tags = item.get("tags") or []
    if tags:
        tag_str = " ".join(f"#{t}" for t in tags if t)
        if tag_str:
            line += f" {tag_str}"
    note = item.get("note", "")
    if note:
        note_preview = note[:60]
        line += f" | {note_preview}"
    item_id = item.get("id", "")
    if item_id:
        line += f" (id: {item_id})"
    return line


def get_schedule_summary(
    user_id: Optional[str] = None,
    start_date: Optional[str] = None,
    days: int = 7,
    include_empty_today: bool = True
) -> str:
    schedule = load_schedule(user_id=user_id)
    today = datetime.now().date()
    start = _parse_schedule_date(start_date) if start_date else today
    if start is None:
        start = today
    days = max(1, min(days, 14))

    day_map = {d.get("date", ""): d for d in schedule.get("days", []) if isinstance(d, dict)}
    lines = ["=== DAILY SCHEDULE ==="]
    had_any = False
    for offset in range(days):
        day = start + timedelta(days=offset)
        day_str = day.strftime("%Y-%m-%d")
        items = day_map.get(day_str, {}).get("items", [])
        include_empty = offset == 0 or (include_empty_today and day == today)
        if not items and not include_empty:
            continue
        lines.append(f"{day_str}:")
        if not items:
            lines.append("- (æš‚æ— å®‰æ’)")
            continue
        had_any = True
        sorted_items = _sort_schedule_items(items)
        max_items = 10
        for item in sorted_items[:max_items]:
            lines.append(f"- {_format_schedule_item(item)}")
        if len(sorted_items) > max_items:
            lines.append(f"- ... è¿˜æœ‰ {len(sorted_items) - max_items} é¡¹æœªå±•ç¤º")

    if not had_any and not include_empty_today:
        return "=== DAILY SCHEDULE ===\n- (æš‚æ— å®‰æ’)"
    return "\n".join(lines)


def delete_file(filename, user_id: Optional[str] = None):
    """åˆ é™¤è®°å¿†åº“ä¸­çš„æ–‡ä»¶ï¼ˆå¹¶æ¸…ç† pin çŠ¶æ€ï¼‰"""
    # ä½¿ç”¨ memory_storage çš„åŸºç¡€å®ç°
    success = _delete_file_impl(filename, user_id)
    if success:
        # åŒæ—¶æ¸…ç† pin çŠ¶æ€
        toggle_pin_status(filename, pin=False, user_id=user_id)
    return success


# --- ç½®é¡¶ (Pin) é€»è¾‘ ---
def toggle_pin_status(filename, pin: bool, user_id: Optional[str] = None):
    """è®¾ç½®æˆ–å–æ¶ˆç½®é¡¶"""
    meta = load_json("meta", default={"pinned_files": []}, user_id=user_id)
    safe_name = os.path.basename(filename)
    if pin:
        if safe_name not in meta["pinned_files"]:
            meta["pinned_files"].append(safe_name)
    else:
        if safe_name in meta["pinned_files"]:
            meta["pinned_files"].remove(safe_name)
    save_json("meta", meta, user_id=user_id)
    return safe_name in meta["pinned_files"]

def get_pinned_content(user_id: Optional[str] = None):
    """è·å–æ‰€æœ‰ç½®é¡¶æ–‡ä»¶çš„å†…å®¹"""
    meta = load_json("meta", default={"pinned_files": []}, user_id=user_id)
    context_str = ""
    for fname in meta["pinned_files"]:
        content = read_file_content(fname, user_id=user_id)
        if content:
            context_str += f"\n--- [Pinned Memory: {fname}] ---\n{content}\n"
    return context_str



def get_pending_reminders_summary(user_id: Optional[str] = None):
    """å°†æŒ‚èµ·çš„é—¹é’Ÿä»»åŠ¡è½¬æ¢ä¸ºè¾ƒä¸ºå¯è¯»çš„æ‘˜è¦"""
    reminders = load_json("pending_reminders", default=[], user_id=user_id)
    if not reminders:
        return "æ— æŒ‚èµ·çš„æé†’ä»»åŠ¡ã€‚"

    summary = []
    now = time.time()
    for reminder in reminders:
        reminder_id = reminder.get('id', '')
        run_at = reminder.get('run_at', 0)
        prompt = reminder.get('prompt', 'æœªçŸ¥ä»»åŠ¡')

        # è®¡ç®—å‰©ä½™æ—¶é—´
        diff = int(run_at - now)
        if diff > 0:
            time_str = f"{diff}ç§’å"
            # å¦‚æœæ—¶é—´å¾ˆé•¿ï¼Œæ˜¾ç¤ºå…·ä½“æ—¥æœŸ
            if diff > 3600:
                dt = datetime.fromtimestamp(run_at)
                time_str = dt.strftime("%m-%d %H:%M")
            summary.append(f"- (ID: {reminder_id}) {prompt} (æ‰§è¡Œæ—¶é—´: {time_str})")

    if not summary:
        return "æ— æŒ‚èµ·çš„æé†’ä»»åŠ¡ã€‚"
    return "ä»¥ä¸‹æ˜¯æé†’ä»»åŠ¡åˆ—è¡¨\n" + "\n".join(summary)

def get_global_context_string(user_id: Optional[str] = None):
    """
    ã€æ ¸å¿ƒå‡½æ•°ã€‘
    èšåˆæ‰€æœ‰ Amaya éœ€è¦"é»˜è®¤"çœ‹è§çš„ä¿¡æ¯ã€‚
    åŒ…æ‹¬ï¼š
    1. Pinned Files (ç”¨æˆ·æ‰‹åŠ¨ç½®é¡¶)
    2. Default Files (ç³»ç»Ÿé»˜è®¤å¯è§ï¼Œå¦‚ routine.json)
    3. Structured Schedule Summary (ç»“æ„åŒ–æ—¥ç¨‹è¡¨æ‘˜è¦)
    4. Pending Reminders (å½“å‰çš„æé†’åˆ—è¡¨)
    """
    context_parts = []
    resolved_user_id = user_id or get_current_user_id()

    # 1. è·å– Pinned Files
    meta = load_json("meta", default={"pinned_files": []}, user_id=resolved_user_id)
    pinned_set = set(meta.get("pinned_files", []))

    # 2. åˆå¹¶ Default Files (å»é‡)
    dir_path = _get_user_memory_dir(resolved_user_id)
    for f in config.DEFAULT_VISIBLE_FILES:
        if os.path.exists(os.path.join(dir_path, f)):
            pinned_set.add(f)
    if SCHEDULE_FILE in pinned_set:
        pinned_set.remove(SCHEDULE_FILE)

    # 3. è¯»å–å¹¶ç»„è£…å†…å®¹
    if pinned_set:
        context_parts.append("=== ğŸ“‚ MEMORY BANK (ACTIVE FILES) ===")
        for fname in pinned_set:
            content = read_file_content(fname, user_id=resolved_user_id)
            if content:
                # åŠ ä¸Šæ–‡ä»¶åä½œä¸ºæ ‡é¢˜ï¼Œæ–¹ä¾¿ AI åŒºåˆ†
                context_parts.append(f"\n--- FILE: {fname} ---\n{content}")

    # 4. æ³¨å…¥ç»“æ„åŒ–æ—¥ç¨‹è¡¨æ‘˜è¦
    schedule_summary = get_schedule_summary(user_id=resolved_user_id)
    if schedule_summary:
        context_parts.append(f"\n{schedule_summary}")

    # 5. æ³¨å…¥ Pending Reminders (è¿™èƒ½æœ‰æ•ˆé˜²æ­¢é‡å¤è®¾ç½®æé†’ï¼)
    reminders_summary = get_pending_reminders_summary(user_id=resolved_user_id)
    context_parts.append(f"\n=== ACTIVE TIMERS (PENDING) ===\n{reminders_summary}")

    full_context = "\n".join(context_parts)
    if len(full_context) > config.GLOBAL_CONTEXT_MAX_CHARS:
        truncated = full_context[:config.GLOBAL_CONTEXT_MAX_CHARS]
        notice = f"[Context trimmed to {config.GLOBAL_CONTEXT_MAX_CHARS} chars]\n"
        return notice + truncated
    return full_context


# --- äº‹ä»¶æ€»çº¿è¯»å†™ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰---
def append_event_to_bus(event: dict, user_id: Optional[str] = None) -> bool:
    """
    çº¿ç¨‹å®‰å…¨åœ°å‘ç³»ç»Ÿäº‹ä»¶æ€»çº¿è¿½åŠ ä¸€æ¡äº‹ä»¶ã€‚
    """
    resolved_user_id = user_id or get_current_user_id()
    if "user_id" not in event:
        event["user_id"] = resolved_user_id
    try:
        payload = json.dumps(event, ensure_ascii=False)
    except TypeError as e:
        logger.error(f"äº‹ä»¶åºåˆ—åŒ–å¤±è´¥: {e}")
        return False

    event_id = event.get("id") or event.get("reminder_id") or "-"
    event_type = event.get("type")
    resolved_user_id = event.get("user_id") or resolved_user_id
    try:
        with _db_lock, _get_db_connection() as conn:
            conn.execute(
                "INSERT INTO sys_events (user_id, event_id, event_type, payload, status, created_at) VALUES (?, ?, ?, ?, ?, ?)",
                (resolved_user_id, event_id, event_type, payload, "pending", time.time())
            )
    except sqlite3.Error as e:
        event_logger.error(f"äº‹ä»¶æ€»çº¿å†™å…¥å¤±è´¥: {e}")
        return False
    event_logger.debug("äº‹ä»¶å†™å…¥æ€»çº¿ type=%s id=%s", event_type, event_id)
    return True


def read_events_from_bus() -> tuple[list[dict], list[str]]:
    """
    çº¿ç¨‹å®‰å…¨åœ°è¯»å–å¹¶æ¸…ç©ºç³»ç»Ÿäº‹ä»¶æ€»çº¿ã€‚
    è¿”å› (events, invalid_lines)ã€‚
    """
    events: list[dict] = []
    invalid_lines: list[str] = []
    try:
        with _db_lock, _get_db_connection() as conn:
            rows = conn.execute(
                "SELECT id, payload, user_id FROM sys_events WHERE status = 'pending' ORDER BY id"
            ).fetchall()
            if not rows:
                return [], []

            valid_ids: list[int] = []
            invalid_ids: list[int] = []

            for row in rows:
                payload = row["payload"]
                row_user_id = row["user_id"]
                try:
                    event = json.loads(payload)
                    if isinstance(event, dict) and "user_id" not in event:
                        event["user_id"] = row_user_id or config.DEFAULT_USER_ID
                    events.append(event)
                    valid_ids.append(row["id"])
                except json.JSONDecodeError as e:
                    event_logger.warning(f"äº‹ä»¶è§£æå¤±è´¥: {e}")
                    invalid_lines.append(payload)
                    invalid_ids.append(row["id"])

            now = time.time()
            if valid_ids:
                placeholders = ",".join(["?"] * len(valid_ids))
                conn.execute(
                    f"UPDATE sys_events SET status = 'processed', processed_at = ? WHERE id IN ({placeholders})",
                    [now, *valid_ids]
                )
            if invalid_ids:
                placeholders = ",".join(["?"] * len(invalid_ids))
                conn.execute(
                    f"UPDATE sys_events SET status = 'invalid', processed_at = ? WHERE id IN ({placeholders})",
                    [now, *invalid_ids]
                )
    except sqlite3.Error as e:
        event_logger.error(f"è¯»å–äº‹ä»¶æ€»çº¿å¤±è´¥: {e}")
        return [], []

    event_logger.debug("äº‹ä»¶æ€»çº¿è¯»å–å®Œæˆ events=%s invalid=%s", len(events), len(invalid_lines))
    return events, invalid_lines

# æ³¨æ„ï¼š_init_db() å·²åœ¨ utils/db.py å¯¼å…¥æ—¶è‡ªåŠ¨è°ƒç”¨
